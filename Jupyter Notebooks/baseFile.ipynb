{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Project Combined*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Make a list of images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(images[4])\n",
    "img2 = img.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by:\n",
    "# http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_trackbar/py_trackbar.html\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.namedWindow('trackbar')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('WU','trackbar',255,255,nothing)\n",
    "cv2.createTrackbar('WL','trackbar',200,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('YU_H','trackbar',110,179,nothing)\n",
    "cv2.createTrackbar('YU_V','trackbar',255,255,nothing)\n",
    "cv2.createTrackbar('YU_S','trackbar',255,255,nothing)\n",
    "cv2.createTrackbar('YL_H','trackbar',90,179,nothing)\n",
    "cv2.createTrackbar('YL_V','trackbar',100,255,nothing)\n",
    "cv2.createTrackbar('YL_S','trackbar',100,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):   \n",
    "    cv2.imshow('image',img2)\n",
    "    # get current positions of four trackbars\n",
    "    WU = cv2.getTrackbarPos('WU','trackbar')\n",
    "    WL = cv2.getTrackbarPos('WL','trackbar')\n",
    "    \n",
    "    YU_H = cv2.getTrackbarPos('YU_H','trackbar')\n",
    "    YU_V = cv2.getTrackbarPos('YU_V','trackbar')\n",
    "    YU_S = cv2.getTrackbarPos('YU_S','trackbar')\n",
    "    YL_H = cv2.getTrackbarPos('YL_H','trackbar')\n",
    "    YL_V = cv2.getTrackbarPos('YL_V','trackbar')\n",
    "    YL_S = cv2.getTrackbarPos('YL_S','trackbar')    \n",
    "    \n",
    "    io = cv2.getTrackbarPos(switch,'image')\n",
    "    \n",
    "    # Filter White\n",
    "    high_threshold = np.array([WU, WU, WU]) #Bright white\n",
    "    low_threshold = np.array([WL, WL, WL]) #Soft White\n",
    "    mask = cv2.inRange(img, low_threshold, high_threshold)\n",
    "    white_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # Filter Yellow\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) #Changing Color-space, HSV is better for object detection\n",
    "    #For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. \n",
    "    high_threshold = np.array([YU_H,YU_V,YU_S]) #Bright Yellow\n",
    "    low_threshold = np.array([YL_H,YL_V,YL_S]) #Soft Yellow   \n",
    "    mask = cv2.inRange(hsv_img, low_threshold, high_threshold)\n",
    "    yellow_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Combine the two above images\n",
    "    filtered_img = cv2.addWeighted(white_img, 1., yellow_img, 1., 0.)     \n",
    "\n",
    "    if io == 0:\n",
    "        img2 = img\n",
    "    else:\n",
    "        img2 = filtered_img\n",
    "\n",
    "    #terminates program\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a black image, a window\n",
    "#img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.namedWindow('trackbarW')\n",
    "cv2.namedWindow('trackbarY')\n",
    "\n",
    "# create trackbars for color change\n",
    "cv2.createTrackbar('WU_H','trackbarW',179,179,nothing)\n",
    "cv2.createTrackbar('WU_V','trackbarW',255,255,nothing)\n",
    "cv2.createTrackbar('WU_S','trackbarW',255,255,nothing)\n",
    "cv2.createTrackbar('WL_H','trackbarW',200,255,nothing)\n",
    "cv2.createTrackbar('WL_V','trackbarW',200,255,nothing)\n",
    "cv2.createTrackbar('WL_S','trackbarW',200,255,nothing)\n",
    "\n",
    "cv2.createTrackbar('YU_H','trackbarY',110,179,nothing)\n",
    "cv2.createTrackbar('YU_V','trackbarY',255,255,nothing)\n",
    "cv2.createTrackbar('YU_S','trackbarY',255,255,nothing)\n",
    "cv2.createTrackbar('YL_H','trackbarY',90,179,nothing)\n",
    "cv2.createTrackbar('YL_V','trackbarY',100,255,nothing)\n",
    "cv2.createTrackbar('YL_S','trackbarY',100,255,nothing)\n",
    "\n",
    "# create switch for ON/OFF functionality\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch, 'image',0,1,nothing)\n",
    "\n",
    "while(1):   \n",
    "    cv2.imshow('image',img2)\n",
    "    # get current positions of four trackbars\n",
    "    WU_H = cv2.getTrackbarPos('WU_H','trackbarW')\n",
    "    WU_V = cv2.getTrackbarPos('WU_V','trackbarW')\n",
    "    WU_S = cv2.getTrackbarPos('WU_S','trackbarW')\n",
    "    WL_H = cv2.getTrackbarPos('WL_H','trackbarW')\n",
    "    WL_V = cv2.getTrackbarPos('WL_V','trackbarW')\n",
    "    WL_S = cv2.getTrackbarPos('WL_S','trackbarW')\n",
    "    \n",
    "    YU_H = cv2.getTrackbarPos('YU_H','trackbarY')\n",
    "    YU_V = cv2.getTrackbarPos('YU_V','trackbarY')\n",
    "    YU_S = cv2.getTrackbarPos('YU_S','trackbarY')\n",
    "    YL_H = cv2.getTrackbarPos('YL_H','trackbarY')\n",
    "    YL_V = cv2.getTrackbarPos('YL_V','trackbarY')\n",
    "    YL_S = cv2.getTrackbarPos('YL_S','trackbarY')    \n",
    "    \n",
    "    io = cv2.getTrackbarPos(switch,'image')\n",
    "    \n",
    "    # Filter White\n",
    "    high_threshold = np.array([WU_H,WU_V,WU_S]) #Bright white\n",
    "    low_threshold = np.array([WL_H,WL_V,WL_S]) #Soft White\n",
    "    mask = cv2.inRange(img, low_threshold, high_threshold)\n",
    "    white_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # Filter Yellow\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) #Changing Color-space, HSV is better for object detection\n",
    "    #For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. \n",
    "    high_threshold = np.array([YU_H,YU_V,YU_S]) #Bright Yellow\n",
    "    low_threshold = np.array([YL_H,YL_V,YL_S]) #Soft Yellow   \n",
    "    mask = cv2.inRange(hsv_img, low_threshold, high_threshold)\n",
    "    yellow_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Combine the two above images\n",
    "    filtered_img = cv2.addWeighted(white_img, 1., yellow_img, 1., 0.)     \n",
    "\n",
    "    if io == 0:\n",
    "        img2 = img\n",
    "    else:\n",
    "        img2 = filtered_img\n",
    "\n",
    "    #terminates program\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break    \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Camera Calibration with OpenCV\n",
    "\n",
    "### Extract object points and image points for camera calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        write_name = 'camera_cal/found/corners_found'+str(idx)+'.jpg'\n",
    "        cv2.imwrite(write_name, img)\n",
    "        cv2.imshow('img', img)        \n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Calibrate, calculate distortion coefficients, and test undistortion on an image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "%matplotlib inline\n",
    "\n",
    "# Test undistortion on an image\n",
    "img = cv2.imread('camera_cal/test_image/test_image.jpg')\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "cv2.imwrite('camera_cal/test_image/test_undist.jpg',dst)\n",
    "\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/camera_cal_dist_pickle.p\", \"wb\" ) )\n",
    "\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Perpespective Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undistort road images as a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list of images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages(images, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(img, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "plotImages(images, ncols=2, cmap=None, prefix_label = 'Original:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages_undistorted(images, mtx, dist, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(img, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "plotImages_undistorted(images, mtx, dist, ncols=2, cmap=None, prefix_label = 'Undistorted:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a function to make sure that transformation source points are always sorted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order points in clock-wise\n",
    "# Inspired by this discussion:\n",
    "# http://stackoverflow.com/questions/1709283/how-can-i-sort-a-coordinate-list-for-a-rectangle-counterclockwise\n",
    "def order_points(pts):\n",
    "    # normalises the input into the [0, 2pi] space, added 0.5*pi to initiate from top left\n",
    "    # which naturally will sort it \"counter-clockwise\"\n",
    "    mx = np.sum(pts.T[0]/len(pts))\n",
    "    my = np.sum(pts.T[1]/len(pts))\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(pts)):\n",
    "        l.append(  (np.math.atan2(pts.T[0][i] - mx, pts.T[1][i] - my) + 2 * np.pi + 0.5 * np.pi) % (2*np.pi)  )\n",
    "    sort_idx = np.argsort(l)\n",
    "    \n",
    "    return pts[sort_idx[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a function to compute perspective transformation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_matrices(pts, img_size):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    src = order_points(pts)\n",
    "    #print(src)\n",
    "    #print(src[3][0])\n",
    "    #print(src[2][0])\n",
    "    \n",
    "    # destination points\n",
    "    '''\n",
    "    dst = np.float32([[0, 0],\n",
    "                      [img_size[0]-1, 0], \n",
    "                      [img_size[0]-1, img_size[1]-1], \n",
    "                      [0, img_size[1]-1]])\n",
    "    '''\n",
    "    dst = np.float32([[src[3][0], 0],\n",
    "                      [src[2][0], 0],\n",
    "                      [src[2][0], img_size[1]],\n",
    "                      [src[3][0], img_size[1]]])\n",
    "    #'''\n",
    "    \n",
    "    print(dst)\n",
    "    # compute the perspective transform matrix and the inverse of it\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "    # return the matrices\n",
    "    return M, Minv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on a road image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "img = cv2.imread(images[0])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)\n",
    "\n",
    "# undistort and get size\n",
    "img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# get the points\n",
    "pts = np.float32([[100,700],[550,450],[750,450],[1200,720]])\n",
    "#print(pts)\n",
    "\n",
    "# get the transform matrices\n",
    "M, Minv = get_transform_matrices(pts, img_size)\n",
    "\n",
    "# transform image\n",
    "warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# transform it back\n",
    "warped_back = cv2.warpPerspective(warped, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "# Visualize it\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('Warped Image', fontsize=20)\n",
    "ax3.imshow(warped_back)\n",
    "ax3.set_title('Warped Back Image', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is function to optimize the choice of source points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-using one of my functions\n",
    "# Modified to crop car hood\n",
    "def trapezoid_vertices(image, bottom_width=0.85,top_width=0.07,height=0.40, car_hood=45):\n",
    "    \"\"\"\n",
    "    Create trapezoid vertices for mask. \n",
    "    Inpus:\n",
    "    image\n",
    "    bottom_width = percentage of image width\n",
    "    top_width = percentage of image width\n",
    "    height = percentage of image height\n",
    "    \"\"\"   \n",
    "    imshape = image.shape\n",
    "    \n",
    "    vertices = np.array([[\\\n",
    "        ((imshape[1] * (1 - bottom_width)) // 2, imshape[0]-car_hood),\\\n",
    "        ((imshape[1] * (1 - top_width)) // 2, imshape[0] - imshape[0] * height + car_hood),\\\n",
    "        (imshape[1] - (imshape[1] * (1 - top_width)) // 2, imshape[0] - imshape[0] * height + car_hood),\\\n",
    "        (imshape[1] - (imshape[1] * (1 - bottom_width)) // 2, imshape[0] - car_hood)]]\\\n",
    "        , dtype=np.int32)\n",
    "    \n",
    "    return vertices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize source points by using a straight road image. Choose source points that warp lane lines to be vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize source points and use straight road to find the for calibration\n",
    "# load image\n",
    "img = cv2.imread('test_images/straight_lines2.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(img.shape)\n",
    "\n",
    "# undistort and get size\n",
    "img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "src = np.array([[262, 677], [580, 460], [703, 460], [1040, 677]]).astype(np.float32)\n",
    "dst = np.array([[262, 720], [262, 0], [1040, 0], [1040, 720]]).astype(np.float32)\n",
    "\n",
    "# get the points by image ratios\n",
    "pts = trapezoid_vertices(img, bottom_width=0.4,top_width=0.092,height=0.4, car_hood=45)  # 1, 0.046, 0.4 --> 1, 0.167, 0,35\n",
    "# 1, 0.115, 0.37,    0.59,0.11,0.43,55\n",
    "pts = pts.reshape(pts.shape[1:])\n",
    "pts = pts.astype(np.float32)\n",
    "#print(pts)\n",
    "\n",
    "# get the transform matrices\n",
    "M, Minv = get_transform_matrices(pts, img_size)\n",
    "\n",
    "# transform image\n",
    "warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# transform it back\n",
    "warped_back = cv2.warpPerspective(warped, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "# Visualize it\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=20)\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('Warped Image', fontsize=20)\n",
    "ax3.imshow(warped_back)\n",
    "ax3.set_title('Warped Back Image', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save transformation matrices!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformation matrices for later use\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"M\"] = M\n",
    "dist_pickle[\"Minv\"] = Minv\n",
    "pickle.dump( dist_pickle, open( \"camera_cal/perspective_trans_matrices.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Thresholding\n",
    "\n",
    "### Let's apply combinations of color and gradient thresholds to generate a binary image where the lane lines are clearly visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the saved camera matrix and distortion coefficients\n",
    "# These are the arrays we calculated using cv2.calibrateCamera()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/camera_cal_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read in the saved perspective transformation matrices\n",
    "# These are the arrays we calculated using cv2.getPerspectiveTransform()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/perspective_trans_matrices.p\", \"rb\" ) )\n",
    "M = dist_pickle[\"M\"]\n",
    "Minv = dist_pickle[\"Minv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start on the thresholding. First with sobel gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Make a list of images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge Inline Pictures\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = \"14, 8\" # or  whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "img = cv2.imread(images[4])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(img), 'with dimesions:', img.shape)\n",
    "\n",
    "# Display Image\n",
    "f, ax = plt.subplots(1, sharex=True, figsize=(14,1*8.7))\n",
    "f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "plt.imshow(img)\n",
    "ax.set_title('Original Image', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the HLS color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLS color space\n",
    "\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "H = hls[:,:,0]\n",
    "L = hls[:,:,1]\n",
    "S = hls[:,:,2]\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(H, cmap='gray') \n",
    "axarr[0].set_title('H channel', fontsize=20)\n",
    "axarr[1].imshow(L, cmap='gray') \n",
    "axarr[1].set_title('L channel', fontsize=20)\n",
    "axarr[2].imshow(S, cmap='gray') \n",
    "axarr[2].set_title('S channel', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore Sobel absolute gradient X threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_min=20\n",
    "thresh_max=100\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# Apply x gradient with the OpenCV Sobel() function\n",
    "# and take the absolute value\n",
    "abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "# Rescale back to 8 bit integer\n",
    "scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "# Create a copy and apply the threshold\n",
    "binary_output = np.zeros_like(scaled_sobel)\n",
    "# Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(2, sharex=True, figsize=(14,2*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(binary_output, cmap='gray') \n",
    "axarr[1].set_title('Sobel Gradient X', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Sobel gradient and HLS color thresholds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(img, s_thresh=(170, 254), sx_thresh=(15, 100)): # 170,255 and 20,100\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSL color space and separate the L channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    combined = np.zeros_like(s_channel)\n",
    "    combined[((s_binary == 1) | (sxbinary == 1))] = 1\n",
    "    return color_binary, combined\n",
    "    \n",
    "color_binary, combined = thresholding(img)\n",
    "\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(color_binary, cmap=None) \n",
    "axarr[1].set_title('Color binary, Green for Gradient and Blue for color threshold', fontsize=20)\n",
    "axarr[2].imshow(combined, cmap='gray') \n",
    "axarr[2].set_title('Gray Scale', fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it on several road images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages_thresholdings(images, mtx, dist, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "        \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)       \n",
    "\n",
    "        # Apply threshold\n",
    "        color_binary, combined = thresholding(img)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(combined, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages_thresholdings(images, mtx, dist, ncols=2, cmap='gray', prefix_label = 'Threshold:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's apply perspective transformation on a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold\n",
    "color_binary, combined = thresholding(img)\n",
    "\n",
    "# transform image\n",
    "warped = cv2.warpPerspective(combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(combined, cmap='gray') \n",
    "axarr[1].set_title('Gray Scale', fontsize=20)\n",
    "axarr[2].imshow(warped, cmap='gray') \n",
    "axarr[2].set_title('warped', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's apply it several test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages_perspective(images, mtx, dist, M, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort, get sizes\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)       \n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "        # Apply threshold\n",
    "        color_binary, combined = thresholding(img)\n",
    "\n",
    "        # transform image\n",
    "        warped = cv2.warpPerspective(combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(warped, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages_perspective(images, mtx, dist, M, ncols=2, cmap='gray', prefix_label = 'Perspective:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's try another method based on first detection project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    (assuming your grayscaled image is called 'gray')\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Or use BGR2GRAY if you read an image with cv2.imread()\n",
    "    # return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "def filter_WhiteYellow(image):\n",
    "    \"\"\"\n",
    "    Filter the image, showing only a range of white and yellow\n",
    "    \"\"\"\n",
    "    # Filter White\n",
    "    threshold = 200 \n",
    "    high_threshold = np.array([255, 255, 255]) #Bright white\n",
    "    low_threshold = np.array([threshold, threshold, threshold]) #Soft White\n",
    "    mask = cv2.inRange(image, low_threshold, high_threshold)\n",
    "    white_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Filter Yellow\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #Changing Color-space, HSV is better for object detection\n",
    "    #For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. \n",
    "    high_threshold = np.array([110,255,255]) #Bright Yellow\n",
    "    low_threshold = np.array([90,100,100]) #Soft Yellow   \n",
    "    mask = cv2.inRange(hsv_img, low_threshold, high_threshold)\n",
    "    yellow_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Combine the two above images\n",
    "    filtered_img = cv2.addWeighted(white_img, 1., yellow_img, 1., 0.)\n",
    "\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "filtered_img = filter_WhiteYellow(img)\n",
    "# Convert image to gray scale\n",
    "gray = grayscale(filtered_img)\n",
    "binary_output2 = np.zeros_like(gray)\n",
    "binary_output2[(gray > 0)] = 1\n",
    "\n",
    "# Display Image\n",
    "f, ax = plt.subplots(1, sharex=True, figsize=(14,1*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "plt.imshow(binary_output2, cmap='gray') \n",
    "ax.set_title('Yellow & White Filter Converted to Gray Scale', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see how it looks like on transformed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages_perspective2(images, mtx, dist, M, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort, get sizes\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)       \n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "        # Apply Yellow & White Filter\n",
    "        filtered_img = filter_WhiteYellow(img)\n",
    "        gray = grayscale(filtered_img)\n",
    "        binary_output2 = np.zeros_like(gray)\n",
    "        binary_output2[(gray > 0)] = 1\n",
    "\n",
    "        # transform image\n",
    "        warped = cv2.warpPerspective(binary_output2, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(warped, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages_perspective2(images, mtx, dist, M, ncols=2, cmap='gray', prefix_label = 'Perspective:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to combine Sobel gradient and Yello/White filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_min=20\n",
    "thresh_max=100\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "# Apply x gradient with the OpenCV Sobel() function\n",
    "# and take the absolute value\n",
    "abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "# Rescale back to 8 bit integer\n",
    "scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "# Create a copy and apply the threshold\n",
    "binary_output = np.zeros_like(scaled_sobel)\n",
    "# Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "\n",
    "# Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "filtered_img = filter_WhiteYellow(img)\n",
    "# Convert image to gray scale\n",
    "gray = grayscale(filtered_img)\n",
    "binary_output2 = np.zeros_like(gray)\n",
    "binary_output2[(gray > 0)] = 1\n",
    "\n",
    "combined = np.zeros_like(binary_output)\n",
    "combined[((binary_output2 == 1) | (binary_output == 1))] = 1\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(4, sharex=True, figsize=(14,4*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(binary_output, cmap='gray') \n",
    "axarr[1].set_title('Sobel Gradient X', fontsize=20)\n",
    "axarr[2].imshow(binary_output2, cmap='gray') \n",
    "axarr[2].set_title('Yellow and White Filter', fontsize=20)\n",
    "axarr[3].imshow(combined, cmap='gray') \n",
    "axarr[3].set_title('Combined', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we try it on several test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages_perspective3(images, mtx, dist, M, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort, get sizes\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)       \n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "        # Sobel gradient X\n",
    "        thresh_min=20\n",
    "        thresh_max=100\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Apply x gradient with the OpenCV Sobel() function\n",
    "        # and take the absolute value\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "        # Rescale back to 8 bit integer\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "        # Create a copy and apply the threshold\n",
    "        binary_output = np.zeros_like(scaled_sobel)\n",
    "        # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "        binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "        \n",
    "        # Apply Yellow & White Filter\n",
    "        filtered_img = filter_WhiteYellow(img)\n",
    "        gray = grayscale(filtered_img)\n",
    "        binary_output2 = np.zeros_like(gray)\n",
    "        binary_output2[(gray > 0)] = 1\n",
    "        \n",
    "        # Combne it\n",
    "        combined = np.zeros_like(binary_output)\n",
    "        combined[((binary_output2 == 1) | (binary_output == 1))] = 1\n",
    "\n",
    "        # transform image\n",
    "        warped = cv2.warpPerspective(combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(warped, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages_perspective3(images, mtx, dist, M, ncols=2, cmap='gray', prefix_label = 'Perspective:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the pipeline using combined gradient and color threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipeline_thresholding2(img, M, img_size, sx_thresh=(15, 100)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "\n",
    "\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(img)\n",
    "    # Convert image to gray scale\n",
    "    gray = grayscale(filtered_img)\n",
    "    binary_output2 = np.zeros_like(gray)\n",
    "    binary_output2[(gray > 0)] = 1\n",
    "\n",
    "    combined = np.zeros_like(binary_output)\n",
    "    combined[((binary_output2 == 1) | (binary_output == 1))] = 1\n",
    "    \n",
    "    warped = cv2.warpPerspective(combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, combined\n",
    "\n",
    "warped, combined = pipeline_thresholding2(img, M, img_size)\n",
    "\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(combined, cmap='gray') \n",
    "axarr[1].set_title('combined', fontsize=20)\n",
    "axarr[2].imshow(warped, cmap='gray') \n",
    "axarr[2].set_title('Warped', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Here is the pipeline using only Yellow & White filter which in my opinon is doing a great job with less computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pipeline_thresholding3(img, M, img_size):\n",
    "\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(img)\n",
    "    # Convert image to gray scale\n",
    "    gray = grayscale(filtered_img)\n",
    "    binary_output2 = np.zeros_like(gray)\n",
    "    binary_output2[(gray > 0)] = 1\n",
    "    \n",
    "    warped = cv2.warpPerspective(binary_output2, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, binary_output2\n",
    "\n",
    "warped, binary_output2 = pipeline_thresholding3(img, M, img_size)\n",
    "\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(binary_output2, cmap='gray') \n",
    "axarr[1].set_title('Yellow and White Filtered', fontsize=20)\n",
    "axarr[2].imshow(warped, cmap='gray') \n",
    "axarr[2].set_title('Warped', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Detect Lane\n",
    "\n",
    "### Let's detect and annotate the lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the saved camera matrix and distortion coefficients\n",
    "# These are the arrays we calculated using cv2.calibrateCamera()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/camera_cal_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read in the saved perspective transformation matrices\n",
    "# These are the arrays we calculated using cv2.getPerspectiveTransform()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/perspective_trans_matrices.p\", \"rb\" ) )\n",
    "M = dist_pickle[\"M\"]\n",
    "Minv = dist_pickle[\"Minv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test the thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge Inline Pictures\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = \"14, 8\" # or  whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_WhiteYellow(image):\n",
    "    \"\"\"\n",
    "    Filter the image, showing only a range of white and yellow\n",
    "    \"\"\"\n",
    "    # Filter White\n",
    "    threshold = 200 \n",
    "    high_threshold = np.array([255, 255, 255]) #Bright white\n",
    "    low_threshold = np.array([threshold, threshold, threshold]) #Soft White\n",
    "    mask = cv2.inRange(image, low_threshold, high_threshold)\n",
    "    white_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Filter Yellow\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #Changing Color-space, HSV is better for object detection\n",
    "    #For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. \n",
    "    high_threshold = np.array([110,255,255]) #Bright Yellow\n",
    "    low_threshold = np.array([90,100,100]) #Soft Yellow   \n",
    "    mask = cv2.inRange(hsv_img, low_threshold, high_threshold)\n",
    "    yellow_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Combine the two above images\n",
    "    filtered_img = cv2.addWeighted(white_img, 1., yellow_img, 1., 0.)\n",
    "\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_thresh(image, sobel_kernel=5, mag_thresh=(50, 200)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "def pipeline_thresholding2(img, M, img_size, sx_thresh=(15, 100)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    binary_output = mag_thresh(img, sobel_kernel=5, mag_thresh=(50, 200))\n",
    "\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(img)\n",
    "    # Convert image to gray scale\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_RGB2GRAY)\n",
    "    binary_output2 = np.zeros_like(gray)\n",
    "    binary_output2[(gray > 0)] = 1\n",
    "\n",
    "    combined = np.zeros_like(binary_output)\n",
    "    combined[((binary_output2 == 1) | (binary_output == 1))] = 1\n",
    "    \n",
    "    warped = cv2.warpPerspective(combined, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, combined\n",
    "\n",
    "\n",
    "def pipeline_thresholding(img, M, img_size):\n",
    "\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(img)\n",
    "    # Convert image to gray scale\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_RGB2GRAY)\n",
    "    binary_output2 = np.zeros_like(gray)\n",
    "    binary_output2[(gray > 0)] = 1\n",
    "    \n",
    "    warped = cv2.warpPerspective(binary_output2, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, binary_output2\n",
    "\n",
    "\n",
    "#reading in an image\n",
    "img = cv2.imread(images[4])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "warped, binary_threshold = pipeline_thresholding(img, M, img_size)\n",
    "\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(binary_threshold, cmap='gray') \n",
    "axarr[1].set_title('Yellow and White Filtered', fontsize=20)\n",
    "axarr[2].imshow(warped, cmap='gray') \n",
    "axarr[2].set_title('Warped', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Apply to several test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages_perspective3(images, mtx, dist, M, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort, get sizes\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.undistort(img, mtx, dist, None, mtx)       \n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \n",
    "        warped, binary_threshold = pipeline_thresholding(img, M, img_size)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(warped, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages_perspective3(images, mtx, dist, M, ncols=2, cmap='gray', prefix_label = 'Perspective:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Sliding Windows and Fit a Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_warped, binary_threshold = pipeline_thresholding(img, M, img_size)\n",
    "\n",
    "# Take a histogram of the bottom half of the image\n",
    "histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "# Create an output image to draw on and  visualize the result\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "\n",
    "\n",
    "# Visualize it\n",
    "f, axarr = plt.subplots(3, sharex=True, figsize=(14,3*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(binary_warped, cmap='gray') \n",
    "axarr[0].set_title('binary_warped', fontsize=20)\n",
    "axarr[1].plot(histogram) \n",
    "axarr[1].set_title('Histogram', fontsize=20)\n",
    "axarr[2].imshow(out_img, cmap='gray') \n",
    "axarr[2].set_title('First initial image', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the peak of the left and right halves of the histogram\n",
    "# These will be the starting point for the left and right lines\n",
    "midpoint = np.int(histogram.shape[0]/2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set height of windows\n",
    "window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "# Identify the x and y positions of all nonzero pixels in the image\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "# Current positions to be updated for each window\n",
    "leftx_current = leftx_base\n",
    "rightx_current = rightx_base\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# Create empty lists to receive left and right lane pixel indices\n",
    "left_lane_inds = []\n",
    "right_lane_inds = []\n",
    "\n",
    "# Step through the windows one by one\n",
    "for window in range(nwindows):\n",
    "    # Identify window boundaries in x and y (and right and left)\n",
    "    win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "    win_y_high = binary_warped.shape[0] - window*window_height\n",
    "    win_xleft_low = leftx_current - margin\n",
    "    win_xleft_high = leftx_current + margin\n",
    "    win_xright_low = rightx_current - margin\n",
    "    win_xright_high = rightx_current + margin\n",
    "    # Draw the windows on the visualization image\n",
    "    cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "    cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "    # Identify the nonzero pixels in x and y within the window\n",
    "    good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "    good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "    # Append these indices to the lists\n",
    "    left_lane_inds.append(good_left_inds)\n",
    "    right_lane_inds.append(good_right_inds)\n",
    "    # If you found > minpix pixels, recenter next window on their mean position\n",
    "    if len(good_left_inds) > minpix:\n",
    "        leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "    if len(good_right_inds) > minpix:        \n",
    "        rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "# Concatenate the arrays of indices\n",
    "left_lane_inds = np.concatenate(left_lane_inds)\n",
    "right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "# Extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "plt.imshow(out_img)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip the sliding windows step once you know where the lines are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you now have a new warped binary image \n",
    "# from the next frame of video (also called \"binary_warped\")\n",
    "# It's now much easier to find line pixels!\n",
    "nonzero = binary_warped.nonzero()\n",
    "nonzeroy = np.array(nonzero[0])\n",
    "nonzerox = np.array(nonzero[1])\n",
    "margin = 100\n",
    "left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "# Again, extract left and right line pixel positions\n",
    "leftx = nonzerox[left_lane_inds]\n",
    "lefty = nonzeroy[left_lane_inds] \n",
    "rightx = nonzerox[right_lane_inds]\n",
    "righty = nonzeroy[right_lane_inds]\n",
    "# Fit a second order polynomial to each\n",
    "left_fit = np.polyfit(lefty, leftx, 2)\n",
    "right_fit = np.polyfit(righty, rightx, 2)\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### let's visualize the result here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to draw on and an image to show the selection window\n",
    "out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "window_img = np.zeros_like(out_img)\n",
    "# Color in left and right line pixels\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "# Generate a polygon to illustrate the search window area\n",
    "# And recast the x and y points into usable format for cv2.fillPoly()\n",
    "left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "plt.imshow(result)\n",
    "plt.plot(left_fitx, ploty, color='yellow')\n",
    "plt.plot(right_fitx, ploty, color='yellow')\n",
    "plt.xlim(0, 1280)\n",
    "plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Radius of Curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have polynomial fits and we can calculate the radius of curvature as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y-value where we want radius of curvature\n",
    "# I'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "y_eval = np.max(ploty)\n",
    "left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "print(left_curverad, right_curverad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So here's a way to repeat the calculation of radius of curvature after correcting for scale in x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "# Fit new polynomials to x,y in world space\n",
    "left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "# Calculate the new radii of curvature\n",
    "left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "# Now our radius of curvature is in meters\n",
    "print(left_curverad, 'm', right_curverad, 'm')\n",
    "# Example values: 632.1 m    626.2 m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image to draw the lines on\n",
    "warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "# Recast the x and y points into usable format for cv2.fillPoly()\n",
    "pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "# Draw the lane onto the warped blank image\n",
    "cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "# Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "# Combine the result with the original image\n",
    "result = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Pipeline, Image and Video\n",
    "\n",
    "### Let's wrap it up and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "# These are the arrays we calculated using cv2.calibrateCamera()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/camera_cal_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read in the saved perspective transformation matrices\n",
    "# These are the arrays we calculated using cv2.getPerspectiveTransform()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/perspective_trans_matrices.p\", \"rb\" ) )\n",
    "M = dist_pickle[\"M\"]\n",
    "Minv = dist_pickle[\"Minv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_WhiteYellow(image):\n",
    "    \"\"\"\n",
    "    Filter the image, showing only a range of white and yellow\n",
    "    \"\"\"\n",
    "    # Filter White\n",
    "    threshold = 200 \n",
    "    high_threshold = np.array([255, 255, 255]) #Bright white\n",
    "    low_threshold = np.array([threshold, threshold, threshold]) #Soft White\n",
    "    mask = cv2.inRange(image, low_threshold, high_threshold)\n",
    "    white_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Filter Yellow\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #Changing Color-space, HSV is better for object detection\n",
    "    #For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. \n",
    "    high_threshold = np.array([110,255,255]) #Bright Yellow\n",
    "    low_threshold = np.array([90,100,100]) #Soft Yellow   \n",
    "    mask = cv2.inRange(hsv_img, low_threshold, high_threshold)\n",
    "    yellow_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Combine the two above images\n",
    "    filtered_img = cv2.addWeighted(white_img, 1., yellow_img, 1., 0.)\n",
    "\n",
    "    return filtered_img\n",
    "\n",
    "def thresholding(image, M):\n",
    "    \"\"\"\n",
    "    Apply Yellow and White Filter and create binary image\n",
    "    \"\"\"\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(image)\n",
    "    # Convert image to gray scale\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_RGB2GRAY)\n",
    "    # Create binary based on detected pixels\n",
    "    binary_threshold = np.zeros_like(gray)\n",
    "    binary_threshold[(gray > 0)] = 1\n",
    "    # Warp the image\n",
    "    warped = cv2.warpPerspective(binary_threshold, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    '''\n",
    "    Keeps track of line.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "\n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "\n",
    "        # radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "\n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "\n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')\n",
    "\n",
    "        # x values for detected line pixels\n",
    "        self.all_x = None\n",
    "\n",
    "        # y values for detected line pixels\n",
    "        self.all_y = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(binary_warped, line):\n",
    "    out_img = (np.dstack((binary_warped, binary_warped, binary_warped)) * 255).astype(np.uint8)\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low,win_y_low), (win_xleft_high,win_y_high), color=(0,255,0), thickness=2) # Green\n",
    "        cv2.rectangle(out_img, (win_xright_low,win_y_low), (win_xright_high,win_y_high), color=(0,255,0), thickness=2) # Green\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    if line == 'left':\n",
    "        return leftx, lefty\n",
    "    elif line == 'right':\n",
    "        return rightx, righty\n",
    "\n",
    "    \n",
    "    \n",
    "def non_sliding(binary_warped, line):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "\n",
    "    left_fit = left_line.current_fit\n",
    "    right_fit = right_line.current_fit\n",
    "\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin))\n",
    "        & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin))\n",
    "        & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    if line == 'left':\n",
    "        return leftx, lefty\n",
    "    elif line == 'right':\n",
    "        return rightx, righty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(start_img):\n",
    "    '''\n",
    "    Incoming image must be RGB!!\n",
    "    '''\n",
    "    start_img = cv2.undistort(start_img, mtx, dist, None, mtx)\n",
    "    binary_warped = thresholding(start_img, M)\n",
    "\n",
    "    # Check if line was detected in previous frame:\n",
    "    if left_line.detected == True:\n",
    "        leftx, lefty = non_sliding(binary_warped, 'left')\n",
    "    elif left_line.detected == False:\n",
    "        leftx, lefty = sliding_window(binary_warped, 'left')\n",
    "        left_line.detected = True\n",
    "    if right_line.detected == True:\n",
    "        rightx, righty = non_sliding(binary_warped, 'right')\n",
    "    elif right_line.detected == False:\n",
    "        rightx, righty = sliding_window(binary_warped, 'right')\n",
    "        right_line.detected = True\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Stash away polynomials\n",
    "    left_line.current_fit = left_fit\n",
    "    right_line.current_fit = right_fit\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, deg=2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, deg=2)\n",
    "\n",
    "    # Calculate radii of curvature in meters\n",
    "    y_eval = np.max(ploty)  # Where radius of curvature is measured\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "\n",
    "    midpoint = np.int(start_img.shape[1]/2)\n",
    "    middle_of_lane = (right_fitx[-1] - left_fitx[-1]) / 2.0 + left_fitx[-1]\n",
    "    offset = (midpoint - middle_of_lane) * xm_per_pix\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warped_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warped = np.dstack((warped_zero, warped_zero, warped_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warped, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    img_size = (start_img.shape[1], start_img.shape[0])\n",
    "    unwarped = cv2.warpPerspective(color_warped, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(start_img, 1, unwarped, 0.3, 0)\n",
    "    radius = np.mean([left_curverad, right_curverad])\n",
    "\n",
    "    # Add radius and offset calculations to top of video\n",
    "    cv2.putText(result,\"L. Lane Radius: \" + \"{:0.2f}\".format(left_curverad/1000) + 'km', org=(50,50), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1, color=(255,255,255), lineType = cv2.LINE_AA, thickness=2)\n",
    "    cv2.putText(result,\"R. Lane Radius: \" + \"{:0.2f}\".format(right_curverad/1000) + 'km', org=(50,100), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1, color=(255,255,255), lineType = cv2.LINE_AA, thickness=2)\n",
    "    cv2.putText(result,\"C. Position: \" + \"{:0.2f}\".format(offset) + 'm', org=(50,150), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1, color=(255,255,255), lineType = cv2.LINE_AA, thickness=2)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge Inline Pictures\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = \"14, 8\" # or  whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Make a list of images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "\n",
    "img = cv2.imread(images[4])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "result = pipeline(img)\n",
    "\n",
    "plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages(images, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Apply pipeline\n",
    "        left_line = Line()\n",
    "        right_line = Line()\n",
    "        result = pipeline(img)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(result, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages(images, ncols=2, cmap='gray', prefix_label = 'Lane Detected:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6 - Pipeline with average of image for annotation\n",
    "\n",
    "### Here we broke the main pipeline in several functions and apply a buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the saved camera matrix and distortion coefficients\n",
    "# These are the arrays we calculated using cv2.calibrateCamera()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/camera_cal_dist_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Read in the saved perspective transformation matrices\n",
    "# These are the arrays we calculated using cv2.getPerspectiveTransform()\n",
    "dist_pickle = pickle.load( open( \"camera_cal/perspective_trans_matrices.p\", \"rb\" ) )\n",
    "M = dist_pickle[\"M\"]\n",
    "Minv = dist_pickle[\"Minv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_WhiteYellow(image):\n",
    "    \"\"\"\n",
    "    Filter the image, showing only a range of white and yellow\n",
    "    \"\"\"\n",
    "    # Filter White\n",
    "    threshold = 200 \n",
    "    high_threshold = np.array([255, 255, 255]) #Bright white\n",
    "    low_threshold = np.array([threshold, threshold, threshold]) #Soft White\n",
    "    mask = cv2.inRange(image, low_threshold, high_threshold)\n",
    "    white_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Filter Yellow\n",
    "    hsv_img = cv2.cvtColor(image, cv2.COLOR_BGR2HSV) #Changing Color-space, HSV is better for object detection\n",
    "    #For HSV, Hue range is [0,179], Saturation range is [0,255] and Value range is [0,255]. \n",
    "    high_threshold = np.array([110,255,255]) #Bright Yellow\n",
    "    low_threshold = np.array([50,50,50]) #Soft Yellow   \n",
    "    mask = cv2.inRange(hsv_img, low_threshold, high_threshold)\n",
    "    yellow_img = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Combine the two above images\n",
    "    filtered_img = cv2.addWeighted(white_img, 1., yellow_img, 1., 0.)\n",
    "\n",
    "    return filtered_img\n",
    "\n",
    "def thresholding(image, M):\n",
    "    \"\"\"\n",
    "    Apply Yellow and White Filter and create binary image\n",
    "    \"\"\"\n",
    "    img_size = (image.shape[1], image.shape[0])\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(image)\n",
    "    # Convert image to gray scale\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_RGB2GRAY)\n",
    "    # Create binary based on detected pixels\n",
    "    binary_threshold = np.zeros_like(gray)\n",
    "    binary_threshold[(gray > 0)] = 1\n",
    "    # Warp the image\n",
    "    warped = cv2.warpPerspective(binary_threshold, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, binary_threshold\n",
    "\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=5, mag_thresh=(50, 200)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "\n",
    "def thresholding2(img, M, sx_thresh=(20, 100)):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Apply x gradient with the OpenCV Sobel() function\n",
    "    # and take the absolute value\n",
    "    abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    binary_output[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    binary_output = mag_thresh(img, sobel_kernel=5, mag_thresh=(30, 100))\n",
    "\n",
    "    # Filter white and Yellow to make it easier for more accurate Canny detection\n",
    "    filtered_img = filter_WhiteYellow(img)\n",
    "    # Convert image to gray scale\n",
    "    gray = cv2.cvtColor(filtered_img, cv2.COLOR_RGB2GRAY)\n",
    "    binary_output2 = np.zeros_like(gray)\n",
    "    binary_output2[(gray > 0)] = 1\n",
    "\n",
    "    binary_threshold = np.zeros_like(binary_output)\n",
    "    binary_threshold[((binary_output2 == 1) | (binary_output == 1))] = 1\n",
    "    \n",
    "    warped = cv2.warpPerspective(binary_threshold, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return warped, binary_output, binary_output2, binary_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Line():\n",
    "    '''\n",
    "    Keeps track of line.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False\n",
    "\n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "\n",
    "        # average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None\n",
    "\n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "\n",
    "        # polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "\n",
    "        # radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None\n",
    "\n",
    "        # distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None\n",
    "\n",
    "        # difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')\n",
    "\n",
    "        # x values for detected line pixels\n",
    "        self.all_x = None\n",
    "\n",
    "        # y values for detected line pixels\n",
    "        self.all_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(binary_warped):\n",
    "    out_img = (np.dstack((binary_warped, binary_warped, binary_warped)) * 255).astype(np.uint8)\n",
    "    histogram = np.sum(binary_warped[int(binary_warped.shape[0]/2):,:], axis=0)\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img, (win_xleft_low,win_y_low), (win_xleft_high,win_y_high), color=(0,255,0), thickness=2) # Green\n",
    "        cv2.rectangle(out_img, (win_xright_low,win_y_low), (win_xright_high,win_y_high), color=(0,255,0), thickness=2) # Green\n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "            \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]  \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    #print(left_fit) # to measure tolerances\n",
    "    \n",
    "    # Stash away polynomials\n",
    "    left_line.current_fit = left_fit\n",
    "    right_line.current_fit = right_fit\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    out_img[ploty.astype('int'),left_fitx.astype('int')] = [0, 255, 255]\n",
    "    out_img[ploty.astype('int'),right_fitx.astype('int')] = [0, 255, 255]\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, deg=2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, deg=2)\n",
    "\n",
    "    # Calculate radii of curvature in meters\n",
    "    y_eval = np.max(ploty)  # Where radius of curvature is measured\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Stash away the curvatures  \n",
    "    left_line.radius_of_curvature = left_curverad  \n",
    "    right_line.radius_of_curvature = right_curverad\n",
    "    \n",
    "    return left_fit, right_fit, left_curverad, right_curverad, out_img\n",
    "\n",
    "    \n",
    "    \n",
    "def non_sliding(binary_warped, left_fit, right_fit):\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin))\n",
    "        & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin))\n",
    "        & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    try:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2) \n",
    "    except:\n",
    "        return left_line.current_fit, right_line.current_fit, left_line.radius_of_curvature, right_line.radius_of_curvature, None\n",
    "    \n",
    "    else:\n",
    "        # Check difference in fit coefficients between last and new fits  \n",
    "        left_line.diffs = left_line.current_fit - left_fit\n",
    "        right_line.diffs = right_line.current_fit - right_fit\n",
    "        if (left_line.diffs[0]>0.001 or left_line.diffs[1]>0.4 or left_line.diffs[2]>150):\n",
    "            return left_line.current_fit, right_line.current_fit, left_line.radius_of_curvature, right_line.radius_of_curvature, None\n",
    "        #print(left_line.diffs)\n",
    "        if (right_line.diffs[0]>0.001 or right_line.diffs[1]>0.4 or right_line.diffs[2]>150):\n",
    "            return left_line.current_fit, right_line.current_fit, left_line.radius_of_curvature, right_line.radius_of_curvature, None\n",
    "        #print(right_line.diffs)\n",
    "        \n",
    "        # Stash away polynomials\n",
    "        left_line.current_fit = left_fit\n",
    "        right_line.current_fit = right_fit\n",
    "\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "        # Fit new polynomials to x,y in world space\n",
    "        left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, deg=2)\n",
    "        right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, deg=2)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        # Calculate radii of curvature in meters\n",
    "        y_eval = np.max(ploty)  # Where radius of curvature is measured\n",
    "        left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "        right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])     \n",
    "\n",
    "        # Stash away the curvatures  \n",
    "        left_line.radius_of_curvature = left_curverad  \n",
    "        right_line.radius_of_curvature = right_curverad\n",
    "\n",
    "        return left_fit, right_fit, left_curverad, right_curverad, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane(undistorted, binary_warped, left_fit, right_fit, left_curverad, right_curverad):\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warped_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warped = np.dstack((warped_zero, warped_zero, warped_zero))    \n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]   \n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    midpoint = np.int(undistorted.shape[1]/2)\n",
    "    middle_of_lane = (right_fitx[-1] - left_fitx[-1]) / 2.0 + left_fitx[-1]\n",
    "    offset = (midpoint - middle_of_lane) * xm_per_pix\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warped, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    img_size = (undistorted.shape[1], undistorted.shape[0])\n",
    "    unwarped = cv2.warpPerspective(color_warped, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted, 1, unwarped, 0.3, 0)\n",
    "    radius = np.mean([left_curverad, right_curverad])\n",
    "\n",
    "    # Add radius and offset calculations to top of video\n",
    "    cv2.putText(result,\"L. Lane Radius: \" + \"{:0.2f}\".format(left_curverad/1000) + 'km', org=(50,50), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1, color=(255,255,255), lineType = cv2.LINE_AA, thickness=2)\n",
    "    cv2.putText(result,\"R. Lane Radius: \" + \"{:0.2f}\".format(right_curverad/1000) + 'km', org=(50,100), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1, color=(255,255,255), lineType = cv2.LINE_AA, thickness=2)\n",
    "    cv2.putText(result,\"C. Position: \" + \"{:0.2f}\".format(offset) + 'm', org=(50,150), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            fontScale=1, color=(255,255,255), lineType = cv2.LINE_AA, thickness=2)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarge Inline Pictures\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = \"14, 8\" # or  whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Make a list of images\n",
    "images = glob.glob('test_images/test*.jpg')\n",
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "detected = False\n",
    "\n",
    "img = cv2.imread(images[4])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "#binary_warped = thresholding2(undistorted, M)\n",
    "binary_warped, binary_output2 = thresholding(undistorted, M)\n",
    "\n",
    "if not detected:\n",
    "    left_fit, right_fit, left_curverad, right_curverad, _ = sliding_window(binary_warped)\n",
    "    detected = True\n",
    "else:\n",
    "    left_fit, right_fit, left_curverad, right_curverad, _ = non_sliding(binary_warped, left_fit, right_fit)\n",
    "\n",
    "result = draw_lane(undistorted, binary_warped, left_fit, right_fit, left_curverad, right_curverad)\n",
    "\n",
    "plt.imshow(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "detected = False\n",
    "\n",
    "img = cv2.imread(images[4])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "binary_warped, binary_output2 = thresholding(undistorted, M)\n",
    "\n",
    "if not detected:\n",
    "    left_fit, right_fit, left_curverad, right_curverad, outimg = sliding_window(binary_warped)\n",
    "    detected = True\n",
    "else:\n",
    "    left_fit, right_fit, left_curverad, right_curverad, _ = non_sliding(binary_warped, left_fit, right_fit)\n",
    "\n",
    "result = draw_lane(undistorted, binary_warped, left_fit, right_fit, left_curverad, right_curverad)\n",
    "\n",
    "# Display Images\n",
    "f, axarr = plt.subplots(5, sharex=True, figsize=(14,5*8.3))\n",
    "f.subplots_adjust(hspace=0.1, wspace=0.05)\n",
    "axarr[0].imshow(img, cmap=None) \n",
    "axarr[0].set_title('Original', fontsize=20)\n",
    "axarr[1].imshow(binary_output2, cmap='gray') \n",
    "axarr[1].set_title('Yellow White', fontsize=20)\n",
    "axarr[2].imshow(binary_warped, cmap='gray') \n",
    "axarr[2].set_title('binary_warped', fontsize=20)\n",
    "axarr[3].imshow(outimg, cmap='gray') \n",
    "axarr[3].set_title('window', fontsize=20)\n",
    "axarr[4].imshow(result, cmap='gray') \n",
    "axarr[4].set_title('result', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plotting function for images\n",
    "def plotImages(images, ncols=1, cmap=None, prefix_label = 'label:'):\n",
    "    \"\"\"\n",
    "    Plot images in a subplot arrangement.\n",
    "    images = python list of images full path\n",
    "    ncols = numbers of columns in the image plot arrangement\n",
    "    prefix_label = prefix label to show on top of images\n",
    "    \"\"\"\n",
    "    from os.path import basename\n",
    "    \n",
    "    nrows = int(np.ceil(len(images) / ncols))\n",
    "    scalesize = nrows*ncols\n",
    "    f, axarr = plt.subplots(nrows, ncols, figsize=(8*ncols, 4*nrows))\n",
    "    f.subplots_adjust(hspace=0.2, wspace=0.05)\n",
    "    axarr = axarr.flatten() # iterate on plots via 1D\n",
    "    \n",
    "    for idx, fname in enumerate(images):\n",
    "        # load image, change color space, undistort\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        #binary_warped = thresholding2(undistorted, M)\n",
    "        binary_warped, binary_output2 = thresholding(undistorted, M)\n",
    "        \n",
    "        # Apply pipeline\n",
    "        left_line = Line()\n",
    "        right_line = Line()\n",
    "        left_fit, right_fit, left_curverad, right_curverad, _ = sliding_window(binary_warped)\n",
    "        result = draw_lane(undistorted, binary_warped, left_fit, right_fit, left_curverad, right_curverad)\n",
    "        \n",
    "        axarr[idx].axis('off')\n",
    "        axarr[idx].imshow(result, cmap=cmap)\n",
    "        axarr[idx].set_title(prefix_label + ' ' + basename(images[idx]), fontsize=20)\n",
    "\n",
    "        \n",
    "plotImages(images, ncols=2, cmap='gray', prefix_label = 'Lane Detected:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processor(nbins=10):\n",
    "    bins = nbins\n",
    "    l_params = deque(maxlen=bins)\n",
    "    r_params = deque(maxlen=bins)\n",
    "    l_radius = deque(maxlen=bins)\n",
    "    r_radius = deque(maxlen=bins)\n",
    "    weights = np.arange(1,bins+1)/bins\n",
    "    def process_image(img):\n",
    "        undistorted = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        #binary_warped = thresholding2(undistorted, M)\n",
    "        binary_warped, binary_output2 = thresholding(undistorted, M)\n",
    "\n",
    "        if len(l_params)==0:\n",
    "            left_fit, right_fit, left_curverad, right_curverad, _ = sliding_window(binary_warped)\n",
    "        else:\n",
    "            left_fit, right_fit, left_curverad, right_curverad, _ = non_sliding(binary_warped,\n",
    "                                                                    np.average(l_params,0,weights[-len(l_params):]),\n",
    "                                                                    np.average(r_params,0,weights[-len(l_params):]))\n",
    "        \n",
    "        l_params.append(left_fit)\n",
    "        r_params.append(right_fit)\n",
    "        l_radius.append(left_curverad)\n",
    "        r_radius.append(right_curverad)\n",
    "        annotated_image = draw_lane(undistorted,\n",
    "                                    binary_warped,\n",
    "                                    np.average(l_params,0,weights[-len(l_params):]),\n",
    "                                    np.average(r_params,0,weights[-len(l_params):]),\n",
    "                                    np.average(l_radius,0,weights[-len(l_params):]),\n",
    "                                    np.average(r_radius,0,weights[-len(l_params):]))\n",
    "        return annotated_image\n",
    "    return process_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video annotated_project_video_avg.mp4.\n",
      "Moviepy - Writing video annotated_project_video_avg.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready annotated_project_video_avg.mp4\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'annotated_project_video_avg.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(get_processor(15)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"annotated_project_video_avg.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out on Challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video annotated_challenge_video_avg.mp4.\n",
      "Moviepy - Writing video annotated_challenge_video_avg.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready annotated_challenge_video_avg.mp4\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "left_line = Line()\n",
    "right_line = Line()\n",
    "white_output = 'annotated_challenge_video_avg.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(get_processor(15)) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"annotated_challenge_video_avg.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
